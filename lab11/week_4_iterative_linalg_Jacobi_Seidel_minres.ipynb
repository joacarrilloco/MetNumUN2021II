{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwNXElZzwVzU"
      },
      "source": [
        "# Simple iteration for systems of linear equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rT6IQiEwVzc"
      },
      "source": [
        "First, generate a random diagonally dominant matrix, for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "xUSNdJ02wVze"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rndm = np.random.RandomState(1234)\n",
        "\n",
        "n = 10\n",
        "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
        "b = rndm.uniform(size=n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWlAW3HIwVzg"
      },
      "source": [
        "# I.  Jacobi iteration\n",
        "\n",
        "Given\n",
        "\n",
        "$$\n",
        "A x = b\n",
        "$$\n",
        "\n",
        "separate the diagonal part $D$,\n",
        "\n",
        "$$ A = D + (A - D) $$\n",
        "\n",
        "and write\n",
        "\n",
        "$$\n",
        "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
        "$$\n",
        "\n",
        "Then iterate\n",
        "\n",
        "$$\n",
        "x_{n + 1} = B x_{n} + c\\;,\n",
        "$$\n",
        "\n",
        "where \n",
        "\n",
        "$$\n",
        "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AZtBx-VwVzh"
      },
      "source": [
        "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lsKzQCbcwVzi"
      },
      "outputs": [],
      "source": [
        "diag_1d = np.diag(A)\n",
        "\n",
        "B = -A.copy()\n",
        "np.fill_diagonal(B, 0)\n",
        "\n",
        "D = np.diag(diag_1d)\n",
        "invD = np.diag(1./diag_1d)\n",
        "BB = invD @ B \n",
        "c = invD @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Hkt3uhD0wVzj"
      },
      "outputs": [],
      "source": [
        "# sanity checks\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "assert_allclose(-B + D, A)\n",
        "\n",
        "\n",
        "# xx is a \"ground truth\" solution, compute it using a direct method\n",
        "xx = np.linalg.solve(A, b)\n",
        "\n",
        "np.testing.assert_allclose(A@xx, b)\n",
        "np.testing.assert_allclose(D@xx, B@xx + b)\n",
        "np.testing.assert_allclose(xx, BB@xx + c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdWTYJEMwVzk"
      },
      "source": [
        "Check that $\\| B\\| \\leqslant 1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTlJwNAHwVzm",
        "outputId": "2ed9a66c-efc0-45d6-ceb0-99dffe2cb405"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36436161983015336"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "np.linalg.norm(BB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsvC6GobwVzp"
      },
      "source": [
        "### Do the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "id": "IBK_JnOdwVzp"
      },
      "outputs": [],
      "source": [
        "n_iter = 50\n",
        "\n",
        "x0 = np.ones(n)\n",
        "x = x0\n",
        "for _ in range(n_iter):\n",
        "    x = BB @ x + c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbPa9YtcwVzr",
        "outputId": "a8e3cc8a-9d37-4945-dfa1-526813451ca0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
              "        1.11022302e-16,  0.00000000e+00, -2.42861287e-17,  0.00000000e+00,\n",
              "       -2.77555756e-17,  1.11022302e-16])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Check the result:\n",
        "\n",
        "A @ x - b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqblDP8swVzs"
      },
      "source": [
        "### Task I.1\n",
        "\n",
        "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
        "\n",
        "\n",
        "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
        "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
        "\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbO6eEaCwVzt",
        "outputId": "aff4f047-01ad-4b8a-bf5f-d4af9830fcb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.11022302e-16  0.00000000e+00 -2.22044605e-16 -1.11022302e-16\n",
            "  1.11022302e-16  0.00000000e+00 -2.42861287e-17  0.00000000e+00\n",
            " -2.77555756e-17  1.11022302e-16]\n",
            "[-0.04242902 -0.04242902 -0.04242902 -0.04242902 -0.04242902 -0.04242902\n",
            " -0.04242902 -0.04242902 -0.04242902 -0.04242902]\n"
          ]
        }
      ],
      "source": [
        "def Jacobi( A, b, iter ):\n",
        "\n",
        "  x = np.ones( n )\n",
        "  for _ in range( iter ):\n",
        "    x = BB @ x + c\n",
        "\n",
        "  return x\n",
        "\n",
        "x = Jacobi( A, b, 100 )\n",
        "\n",
        "print( A @ x - b )\n",
        "\n",
        "#reducing elements of the diagonal by 1%\n",
        "A1 = A - np.diag( A ) / 100\n",
        "x1 = Jacobi( A1, b, 100 )\n",
        "\n",
        "print( A1 @ x1 - b )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJYYz16UwVzu"
      },
      "source": [
        "# II. Seidel's iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoHOqi-owVzv"
      },
      "source": [
        "##### Task II.1\n",
        "\n",
        "Implement the Seidel's iteration. \n",
        "\n",
        "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smF1yniKwVzv",
        "outputId": "e3961926-a28e-43fc-9f7f-b33b9a8c331a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.00000000e+00 -1.11022302e-16  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -1.73472348e-17  0.00000000e+00\n",
            "  0.00000000e+00 -1.11022302e-16]\n",
            "0 2.0642489862459183\n",
            "1 0.2921553884672586\n",
            "2 0.020168897159971992\n",
            "3 0.0006626917588744586\n",
            "4 5.890910715462774e-05\n",
            "5 3.512188242341035e-06\n",
            "6 1.6509251992006011e-07\n",
            "7 1.5276279921693323e-08\n",
            "8 5.525532375812141e-10\n",
            "9 5.396386130602174e-11\n",
            "10 2.716449659983224e-12\n",
            "11 1.5779115716809045e-13\n",
            "12 1.2517128008334558e-14\n",
            "13 5.924633063968824e-16\n",
            "14 1.9506192212679625e-16\n",
            "15 1.5796464744355657e-16\n",
            "16 1.5796464744355657e-16\n",
            "17 1.5796464744355657e-16\n",
            "18 1.5796464744355657e-16\n",
            "19 1.5796464744355657e-16\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def gauss_seidel(A, b, max_iterations=10000):\n",
        "    \n",
        "    x = np.zeros_like(b, dtype=np.double)\n",
        "    \n",
        "    #Iterate\n",
        "    for k in range(max_iterations):\n",
        "        \n",
        "        x_old  = x.copy()\n",
        "        \n",
        "        #Loop over rows\n",
        "        for i in range(A.shape[0]):\n",
        "            x[i] = (b[i] - np.dot(A[i,:i], x[:i]) - np.dot(A[i,(i+1):], x_old[(i+1):])) / A[i ,i]\n",
        "            \n",
        "    return x\n",
        "\n",
        "x = gauss_seidel( A, b, 100 )\n",
        "\n",
        "print( A @ x - b )\n",
        "\n",
        "\n",
        "for iter in range(0, 20, 1):\n",
        "  x = gauss_seidel( A, b, iter )\n",
        "  print( iter, np.linalg.norm( A @ x - b) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxqz7rkHwVzw"
      },
      "source": [
        "# III. Minimum residual scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovqmNNyVwVzx"
      },
      "source": [
        "### Task III.1\n",
        "\n",
        "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
        "\n",
        "(50% of the grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7udb97xwVzy",
        "outputId": "12a6c90a-4159-42b7-ff01-56b21a529e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.049458091915919704\n",
            "0.06632815899696641\n",
            "0.05646528371934232\n",
            "0.059136861448334216\n",
            "0.056149365850671734\n",
            "0.05962056630691936\n",
            "0.055321259622594446\n",
            "0.06019139542967882\n",
            "0.054726519624859894\n",
            "0.06091835471785148\n",
            "0.054788794259621576\n",
            "0.06154317282841529\n",
            "0.055177210974496134\n",
            "0.06162125644817706\n",
            "0.05514529510209265\n",
            "0.06170111966684046\n",
            "0.054725649763148976\n",
            "0.06212081019990162\n",
            "0.054002133608905656\n",
            "0.06437401757338992\n",
            "0.05401091580604399\n",
            "0.06011645923749508\n",
            "0.0627115085769417\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "0.06413230252109958\n",
            "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 3.46944695e-18 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00]\n"
          ]
        }
      ],
      "source": [
        "def min_residual( A, b, iter ):\n",
        "\n",
        "  x = np.ones( n )\n",
        "\n",
        "  for _ in range( n_iter ):\n",
        "\n",
        "    #compute previous residual\n",
        "    residual = A @ x - b\n",
        "\n",
        "    tau = np.dot( residual, A @ residual ) / np.dot( A @ residual, A @ residual )\n",
        "\n",
        "    print( tau )\n",
        "    x -= tau * residual\n",
        "\n",
        "  return x\n",
        "\n",
        "x = min_residual( A, b, 40 )\n",
        "print( A @ x - b )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "week_4_iterative_linalg_Jacobi_Seidel_minres.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}